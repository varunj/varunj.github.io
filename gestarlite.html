<!DOCTYPE html>
<html lang="en-us">
<head>
	<meta name="googlebot" content="noindex">
	<meta charset="UTF-8">
	<title>GestARLite</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="theme-color" content="#a90329">
	<link rel="stylesheet" type="text/css" href="publications_stylesheets/normalize.css" media="screen">
	<link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" href="publications_stylesheets/stylesheet.css" media="screen">
	<link rel="stylesheet" type="text/css" href="publications_stylesheets/github-light.css" media="screen">
	<link rel="shortcut icon" href="publications_res/gestarlite_favicon.ico" />
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
		ga('create', 'UA-101653083-3', 'auto');
		ga('send', 'pageview');
	</script>

</head>

<body>
	<section class="page-header">
		<h1 class="project-name">GestARLite</h1>
		<h2 class="project-tagline">An On-Device Pointing Finger Based Gestural Interface for Smartphones and Video See-Through Headmounts</h2>
		<h2 class="project-authors">Varun Jain, Gaurav Garg, Ramakrishna Perla, Ramya Hebbalaguppe</h2>
		<a href="#video1" class="btn">Demo Video</a>
		<a href="https://drive.google.com/file/d/1WjplySGgSS_SO1lK4Id81w3Jw1JjUbvn/view?usp=sharing" target="_blank" class="btn">GestARLite Android APK</a>
		<a href="https://drive.google.com/file/d/1SU4XSr4-Dz9K31PGzURTwk7-F4tUirDX/view?usp=sharing" target="_blank" class="btn">AirPen Android APK</a>
	</section>

	<section class="main-content">
		<h3><a id="welcome-to-GestARLite" class="anchor" href="#welcome-to-GestARLite" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Welcome to GestARLite</h3>
		<p><img src="publications_res/gestarlite_fig_application.png"></p>
		<p align="justify"> Hand gestures are proved to be most intuitive in the field of Mixed Reality (MR). However, most accurate gesture recognition can be achieved only through the state-of-the-art deep learning models. Despite the robustness of these deep learning models, they are generally computationally expensive and obtaining real-time performance on-device is still a challenge. In this paper, we propose a hand gesture recognition framework in First Person View(FPV) for wearable devices. The models are trained on a GPU machine and ported on to an Android device for its use with frugal wearable devices such as <a href="https://vr.google.com/cardboard/">Google Cardboard</a> and VR Box etc. The proposed hand gesture recognition framework is driven by cascade of state-of-the-art deep learning models - MobileNetV2 for localising the hand followed by a Bi-LSTM model for gesture classification. We extensively evaluate our models on an academic dataset and demonstrate the results in terms of accuracy and recognition turn-around-time on mobile devices. The overall framework achieves classification accuracy of 80% on EgoGestAR video dataset.


		<h3><a id="the-idea" class="anchor" href="#the-idea" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Idea</h3>
		<p><img src="publications_res/gestarlite_fig_framework.png"></p>
		<p align="justify">In this work, we present a neural network architecture comprising of a base MobileNetv2 network for hand candidate detection. This is followed by our Fingertip Regressor that outputs the spatial location of fingertip.  The Bi-LSTM effectively captures the dynamic motion of user gesture that aids in classification. </p>


		<h3><a id="fingertip-regressor" class="anchor" href="#fingertip-regressor" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Fingertip Regressor</h3>
		<p><img src="publications_res/gestarlite_fig_regressionframework.png"></p>
		<p align="justify">Figure above shows the overview of our proposed fingertip regressor architecture for fingertip localization. The input to the network is 3x99x99 sized RGB images. The network consists of 6 convolutional blocks, each with different convolutional layers followed by a max-pooling layer. Finally, we get 2 coordinates denoting fingertip spatial location. </p>


		<h3><a id="EgoGestAR-dataset" class="anchor" href="#EgoGestAR-dataset" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>EgoGestAR Dataset</h3>
		<p><img src="https://raw.githubusercontent.com/varunj/EgoGestAR/master/ztemp_cvpreccv_webpage/pointgestar_img/fig4_fig5_hor.png""></p>
		<p align="justify">We collected the data from 50 subjects in our research lab with ages in the range 21 to 50 with average age 27.8 years. The dataset consists of 2500 gesture patterns where each subject recorded 5 samples of each gesture. The gestures were recorded by mounting a 10.1 inch display HP Pro Tablet to a wall. The gesture pattern drawn by a user's index finger on a touch interface application with position sensing region was stored. The data was captured at a resolution of 640 x 480. Figure above describes the standard input sequences shown to the users before data collection and a sample subset of gestures from the dataset showing the variability introduced by the subjects. Statistics of the EgoGestAR dataset is shown below. The dataset is available <a href="https://github.com/varunj/EgoGestAR">here</a>. </p>


		<!-- <h3><a id="authors" class="anchor" href="#authors" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Authors</h3>
		<div class="authors-wrapper">
			<div class="authors-item">
				<a href="https://www.linkedin.com/in/xxx/""><div class="circle"><img src="" width="140" height="140"/></div></a>
				<p>xxx</p>
			</div>
			<div class="authors-item">
				<a href="https://www.linkedin.com/in/xxx/"><div class="circle"><img src="" width="140" height="140"/></div></a>
				<p>xxx</p>
			</div>
			<div class="authors-item">
				<a href="https://www.linkedin.com/in/xxx/"><div class="circle"><img src="" width="140" height="140"/></div></a>
				<p>xxx</p>
			</div>
		</div> -->


		<h3><a id="video1" class="anchor" href="#video1" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Demo Video: 1</h3>
		<div class="video-responsive">
			<iframe width="560" height="315" src="https://www.youtube.com/embed/UEc32rdqBrs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
		</div>
		
	</section>

</body>
</html>
